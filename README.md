# 🎥 무비 랭크

검색 및 안정적인 동시성 제어를 통해 **대규모 데이터 환경**에서도 사용자에게 최적화된 영화 정보 탐색 경험을 제공하는 **백엔드 서비스**입니다.

---

## 👥 팀 구성
- 유운선 — 검색 담당  
- 윤석호 — 유저 담당  
- 김석준 — 감독·배우·캐스트 담당  
- 이동찬 — 리뷰 담당  
- 박유현 — 영화 담당

---

## 🎯 프로젝트 설명

이 프로젝트는 **영화 데이터셋**을 기반으로 다음과 같은 기능을 제공합니다:

- 🔎 **실시간 검색** : 영화, 배우, 감독, 캐스트 등의 정보를 빠르게 탐색  
- 📖 **상세 정보 조회** : 영화 및 관련 인물의 핵심 정보를 확인  
- 📝 **리뷰 기능** : 사용자가 작성한 리뷰를 등록 및 관리  
- ❤️ **좋아요 기능** : 리뷰에 대한 사용자 피드백 제공  

이 서비스를 통해 사용자는 방대한 영화 데이터 속에서도 **빠르고 안정적인 정보 탐색**을 누릴 수 있습니다.

---

## 🚀 프로젝트 핵심 목표

1. **대규모 데이터 환경에서도 빠른 검색 성능 확보**
   - DB 인덱스 최적화를 통해 Full Table Scan을 Range Scan으로 개선.
   - 10만 건 이상의 데이터셋에서도 평균 응답 시간을 **100ms 이내**로 단축.

2. **안정적인 동시성 제어**
   - PESSIMISTIC_WRITE 락을 활용하여 Lost Update 문제 해결.
   - 리뷰 좋아요/검색어 카운트 증가 등 조회 후 증가 로직의 **원자성** 보장.

3. **서비스 확장성과 안정성 강화**
   - Local Cache에서 Redis 기반 분산 캐시로 전환하여 **Scale-out 지원**.
   - k6 부하 테스트를 통해 평균 응답 시간 **35% 이상 감소** 검증.

4. **운영 및 유지보수 효율성 제고**
   - 캐시 무효화 전략(@CacheEvict) 적용으로 데이터 일관성 확보.
   - Redis 직렬화/역직렬화 오류 해결로 안정적인 캐싱 로직 운영.

---

## 🔑 KEY SUMMARY

- **인덱싱**: 풀 테이블 스캔을 범위 스캔으로 전환 → **응답속도 약 28배 향상** (100,000개 데이터)  
- **동시성 제어**: DB 레벨 `PESSIMISTIC_WRITE` 적용 → Lost Update 제거, Count 증가의 **원자성 보장**  
- **캐싱(Redis)**: k6 부하 테스트(7분, 50 VU, 50,000 더미) 결과 → **평균 응답시간 -35.74% / p95 -35.71%**  

---

## 💡 기술적 의사 결정
프로젝트를 진행하면서 겪었던 핵심 기술적 고민과 이를 해결한 상세 과정입니다.

<details>
<summary>1. 인덱싱 최적화를 통한 검색 성능 28배 향상</summary>

데이터베이스에 10만 건 이상의 데이터가 적재되면서, 사용자의 핵심 탐색 경험인 검색 API의 응답 속도가 현저히 저하되는 문제가 발생했습니다.

### 📌 인덱싱을 통한 검색 성능 개선

| 항목        | 상세 내용 |
|-------------|-----------|
| **내가 구현한 기능** | 영화, 배우, 캐스트 등의 핵심 정보 검색 API |
| **주요 로직** | 사용자가 입력한 키워드를 기반으로 DB에서 데이터를 조회하는 로직 |
| **배경** | 초기 쿼리 작성 시, WHERE 절 조건이 인덱스를 효과적으로 활용하지 못해 대규모 데이터 환경에서 Full Table Scan 발생 → 검색 응답 시간이 수 초대로 지연됨 |
| **요구사항** | 10만 건 이상의 데이터셋에서도 **100ms 이내**의 검색 응답 속도를 확보하여 사용자 경험 최적화 |
| **선택지** | 1. DB 인덱스 최적화 <br> 2. 전문 검색 엔진 도입 |
| **선택 사유** | 초기 프로젝트 범위와 인프라 복잡도를 고려하여 **DB 인덱스 최적화**를 우선 선택. 기존 DB 기능을 활용하는 것이 비용 및 운영 효율성 측면에서 유리하다고 판단 |
| **결과** | 인덱싱 추가를 통해 **Full Table Scan → 범위 스캔**으로 변경, 응답 시간을 약 **28배 이상 향상** |


</details>

<details>
<summary>2. Redis 기반 캐싱 시스템 구축 및 k6 성능 검증</summary>

잦은 요청이 발생하는 배우 정보 조회 API에 대해 응답 속도를 개선하고, 서비스 확장성을 확보하기 위해 캐싱을 도입했습니다.

### 📌 Redis 캐싱 적용 및 성능 개선

| 항목        | 상세 내용 |
|-------------|-----------|
| **내가 구현한 기능** | 배우 검색 API의 캐싱 적용 및 Redis로의 전환 |
| **주요 로직** | 배우 정보 조회 시, Redis 캐시를 먼저 확인하고 없으면 DB에서 조회 후 캐시에 저장하는 **Cache-Aside 전략** 사용 |
| **배경** | 로컬 캐시 사용 시 서버 인스턴스 간 **데이터 불일치 문제** 발생 → 서비스 안정성 저해 및 Scale-out 불가능 |
| **요구사항** | 단순 속도 향상뿐 아니라, **여러 인스턴스 간 일관성 유지 + 수평 확장 가능한 캐싱 아키텍처** 구축 |
| **선택지** | 1. Local Cache <br>2. **Redis** |
| **선택 사유** | 서비스 **안정성 및 확장성 확보**를 최우선 목표로 두고 Redis로 전환. 분산 캐시를 통해 데이터 일관성을 유지하고 메모리 부담을 분산 |
| **검증** | `k6`를 활용하여 **7분간 최대 50 VU** 부하 테스트 (5만 건 더미 데이터셋) 진행 |
| **결과** | 평균 응답 시간 **35.74% 감소**, p95 응답 시간 **35.71% 감소** |

</details>

<details>
<summary>3. DB 레벨 락을 이용한 동시성 제어 및 데이터 원자성 보장</summary>

여러 사용자가 동시에 Count를 증가시키는 작업(예: 리뷰 좋아요)을 수행할 때 발생하는 데이터 무결성 문제를 해결했습니다.

### 📌 동시성 제어를 통한 Count 증가 로직 안정화

| 항목        | 상세 내용 |
|-------------|-----------|
| **내가 구현한 기능** | 리뷰 좋아요/취소, 검색어 카운트 증가 등 '조회 후 증가' 방식의 업데이트 로직 |
| **주요 로직** | 트랜잭션 시작 시 특정 레코드에 **락을 걸고**, Count를 증가시킨 후 트랜잭션 종료 시 락 해제 |
| **배경** | `COUNT = COUNT + 1` 로직이 DB 조회 + 업데이트 두 단계로 실행 → 동시 요청 시 다른 트랜잭션이 끼어들어 **Lost Update 문제 발생** |
| **요구사항** | 동시성 요청 환경에서도 Count 증가의 **원자성** 보장 및 데이터 신뢰성 확보 |
| **선택지** | 1. 낙관적 락 <br>2. 비관적 락 |
| **선택 사유** | 동시 요청이 빈번하고 충돌 가능성이 높은 Count 증가 로직에는 **DB 레벨 비관적 락**을 적용. 충돌 발생 시 재시도 비용이 적고 안정성이 높아 Race Condition을 원천 차단 가능 |
| **결과** | 동시성 제어를 통해 **Lost Update 문제를 방지**하고, Count 증가 로직의 **원자성을 보장** |


</details>

## 🚨 트러블 슈팅
프로젝트 안정성을 위해 해결했던 핵심 트러블 슈팅 사례와 기술적 의사결정 과정을 설명합니다.

<details>
<summary>1. Redis 락 기반 리뷰 좋아요 중복/누락 문제 해결</summary>

문제 배경: 여러 사용자가 동시에 같은 리뷰에 좋아요를 누를 경우, 좋아요 수를 단순 조회 → 증가 방식으로 처리하던 로직에서 동시성 문제로 인해 좋아요 수가 정확히 반영되지 않거나 중복 증가하는 현상 발생.

해결 방안: 좋아요 요청에 대해 Redis 기반의 락 처리 방식을 적용하여 임계 영역을 보호하고 원자성을 확보했습니다.

기술적 의사결정: DB 락 대신 Redis 분산 락을 사용하여 DB 부하를 줄이고 애플리케이션 레벨에서 동시성을 제어하여 성능과 안정성을 동시에 확보했습니다.

결과: 동시 요청 환경에서도 정확한 좋아요 수 집계가 가능해졌으며, 사용자 피드백 기능의 신뢰성과 안정성이 향상되었습니다.

</details>

<details>
<summary>2. 비동기 검색어 기록 카운트 누락 방지 및 일관성 확보</summary>

문제 배경: @Async로 비동기 분리된 검색어 기록 로직에 여러 요청이 동시에 접근하여 동일 검색어의 카운트가 누락되는 현상 발생.

해결 방안 (1): 레포지토리 계층에 **비관적 락을 적용하여 특정 검색 레코드를 조회하는 순간 다른 트랜잭션의 접근을 차단하여 원자성을 확보했습니다.

해결 방안 (2): INSERT 충돌 시 재시도 로직을 추가하여 카운트 누락을 방지하고, 트랜잭션 완료 후 @CacheEvict를 실행하여 캐싱된 검색어 목록의 일관성을 확보했습니다.

결과: 비동기 환경에서 데이터 무결성을 유지하면서도, 메인 스레드의 응답 속도에 영향을 주지 않고 검색어 기록 기능을 안정적으로 운영할 수 있게 되었습니다.

</details>

<details>
<summary>3. Redis DTO 역직렬화 ClassCastException 해결</summary>

문제 배경: Redis에 DTO 객체를 저장하고 다시 꺼낼 때, 타입 정보가 유실되어 LinkedHashMap 형태로 역직렬화되면서 ClassCastException이 발생. 이는 커스텀 ObjectMapper 사용 시 기본 다형성 설정이 초기화되어 발생한 문제였습니다.

해결 방안: 커스텀 ObjectMapper 설정에 타입 정보를 포함시키는 설정을 추가했습니다.

기술적 의사결정: Spring Data Redis의 기본 직렬화 설정에 의존하기보다, 커스텀 ObjectMapper에 명시적으로 DTO의 타입을 포함하여 안전한 역직렬화를 보장하도록 설정했습니다.

결과: DTO가 정확한 타입으로 역직렬화되도록 보장하여 서비스의 안정성을 확보하고 런타임 오류를 방지했습니다.

</details>
